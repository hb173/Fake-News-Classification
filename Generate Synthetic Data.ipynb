{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "news_train = pd.read_csv(\n",
    "    \"/Users/mohammadanas/Desktop/Duke MIDS/Fall 2021/NLP/NLP Final Project/data/Fake_news_data.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>Huma’s Weiner Dogs Hillary</td>\n",
       "      <td>Steve Sailer</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>Mohamad Khweis: Another “Virginia Man” (Palest...</td>\n",
       "      <td>James Fulford</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>A Connecticut Reader Reports Record Voter Regi...</td>\n",
       "      <td>VDARE.com Reader</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>470</td>\n",
       "      <td>BULLETIN: There ARE Righteous Jews For Trump!;...</td>\n",
       "      <td>admin</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>Казахстан на страже ядерной безопасности | Нов...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141</th>\n",
       "      <td>20141</td>\n",
       "      <td>Thomas Frank Explores Whether Hillary Clinton ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20242</th>\n",
       "      <td>20242</td>\n",
       "      <td>Radio Derb Transcript For October 21 Up: The M...</td>\n",
       "      <td>John Derbyshire</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20264</th>\n",
       "      <td>20264</td>\n",
       "      <td>Pro-sovereignty Legislators Demand That Admini...</td>\n",
       "      <td>Brenda Walker</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20513</th>\n",
       "      <td>20513</td>\n",
       "      <td>SAID IN SPANISH: A Mexican Governor Meddles In...</td>\n",
       "      <td>Allan Wall</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20558</th>\n",
       "      <td>20558</td>\n",
       "      <td>Кто любит Стивена Сигала?</td>\n",
       "      <td>Жанна Ивченко</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "82        82                         Huma’s Weiner Dogs Hillary   \n",
       "169      169  Mohamad Khweis: Another “Virginia Man” (Palest...   \n",
       "295      295  A Connecticut Reader Reports Record Voter Regi...   \n",
       "470      470  BULLETIN: There ARE Righteous Jews For Trump!;...   \n",
       "492      492  Казахстан на страже ядерной безопасности | Нов...   \n",
       "...      ...                                                ...   \n",
       "20141  20141  Thomas Frank Explores Whether Hillary Clinton ...   \n",
       "20242  20242  Radio Derb Transcript For October 21 Up: The M...   \n",
       "20264  20264  Pro-sovereignty Legislators Demand That Admini...   \n",
       "20513  20513  SAID IN SPANISH: A Mexican Governor Meddles In...   \n",
       "20558  20558                          Кто любит Стивена Сигала?   \n",
       "\n",
       "                 author text  label  \n",
       "82         Steve Sailer   []      1  \n",
       "169       James Fulford   []      1  \n",
       "295    VDARE.com Reader   []      1  \n",
       "470               admin   []      1  \n",
       "492                 NaN   []      1  \n",
       "...                 ...  ...    ...  \n",
       "20141               NaN   []      1  \n",
       "20242   John Derbyshire   []      1  \n",
       "20264     Brenda Walker   []      1  \n",
       "20513        Allan Wall   []      1  \n",
       "20558     Жанна Ивченко   []      1  \n",
       "\n",
       "[121 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We just conduct EDA and go over the dataset as whole and \n",
    "# see if there are any flaws in the structure that need to be corrected \n",
    "# We make a copy of the data and make a perform some analysis\n",
    "# After doing some preprocessing steps we note that these data entries have no text available \n",
    "# We filter out the IDS of these data entries \n",
    "\n",
    "\n",
    "news_train_eda = news_train.copy()\n",
    "news_train_eda['text'] = news_train_eda['text'].str.lower()\n",
    "news_train_eda['text'] = news_train_eda['text'].replace('[^A-Za-z\\s]','', regex=True)\n",
    "news_train_eda['text'] = news_train_eda['text'].str.split()\n",
    "ids = list(news_train_eda.loc[news_train_eda['text'].str.len() == 0 ,]['id'])\n",
    "news_train_eda.loc[news_train['id'].isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>Huma’s Weiner Dogs Hillary</td>\n",
       "      <td>Steve Sailer</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>Mohamad Khweis: Another “Virginia Man” (Palest...</td>\n",
       "      <td>James Fulford</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>A Connecticut Reader Reports Record Voter Regi...</td>\n",
       "      <td>VDARE.com Reader</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>470</td>\n",
       "      <td>BULLETIN: There ARE Righteous Jews For Trump!;...</td>\n",
       "      <td>admin</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>Казахстан на страже ядерной безопасности | Нов...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>В ноябре 2016 г. Мажилис Парламента Республики...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141</th>\n",
       "      <td>20141</td>\n",
       "      <td>Thomas Frank Explores Whether Hillary Clinton ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20242</th>\n",
       "      <td>20242</td>\n",
       "      <td>Radio Derb Transcript For October 21 Up: The M...</td>\n",
       "      <td>John Derbyshire</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20264</th>\n",
       "      <td>20264</td>\n",
       "      <td>Pro-sovereignty Legislators Demand That Admini...</td>\n",
       "      <td>Brenda Walker</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20513</th>\n",
       "      <td>20513</td>\n",
       "      <td>SAID IN SPANISH: A Mexican Governor Meddles In...</td>\n",
       "      <td>Allan Wall</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20558</th>\n",
       "      <td>20558</td>\n",
       "      <td>Кто любит Стивена Сигала?</td>\n",
       "      <td>Жанна Ивченко</td>\n",
       "      <td>Политика \\nПомните первые видеосалоны 1990-х, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "82        82                         Huma’s Weiner Dogs Hillary   \n",
       "169      169  Mohamad Khweis: Another “Virginia Man” (Palest...   \n",
       "295      295  A Connecticut Reader Reports Record Voter Regi...   \n",
       "470      470  BULLETIN: There ARE Righteous Jews For Trump!;...   \n",
       "492      492  Казахстан на страже ядерной безопасности | Нов...   \n",
       "...      ...                                                ...   \n",
       "20141  20141  Thomas Frank Explores Whether Hillary Clinton ...   \n",
       "20242  20242  Radio Derb Transcript For October 21 Up: The M...   \n",
       "20264  20264  Pro-sovereignty Legislators Demand That Admini...   \n",
       "20513  20513  SAID IN SPANISH: A Mexican Governor Meddles In...   \n",
       "20558  20558                          Кто любит Стивена Сигала?   \n",
       "\n",
       "                 author                                               text  \\\n",
       "82         Steve Sailer                                                      \n",
       "169       James Fulford                                                      \n",
       "295    VDARE.com Reader                                                      \n",
       "470               admin                                                      \n",
       "492                 NaN  В ноябре 2016 г. Мажилис Парламента Республики...   \n",
       "...                 ...                                                ...   \n",
       "20141               NaN                                                      \n",
       "20242   John Derbyshire                                                      \n",
       "20264     Brenda Walker                                                      \n",
       "20513        Allan Wall                                                      \n",
       "20558     Жанна Ивченко  Политика \\nПомните первые видеосалоны 1990-х, ...   \n",
       "\n",
       "       label  \n",
       "82         1  \n",
       "169        1  \n",
       "295        1  \n",
       "470        1  \n",
       "492        1  \n",
       "...      ...  \n",
       "20141      1  \n",
       "20242      1  \n",
       "20264      1  \n",
       "20513      1  \n",
       "20558      1  \n",
       "\n",
       "[121 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# However, the text column above is a copy of a generated data with \n",
    "# some proprocessing steps already performed on it\n",
    "# We use those IDs to get an idea of how the actual data entries of this data looks like\n",
    "# We see that either there are no ids or there are the text is not in English language\n",
    "news_train.loc[news_train['id'].isin(ids)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resolve this we replace the \"text\" of the sentences we our \"title\"\n",
    "news_train.loc[news_train['id'].isin(ids) , 'text'] = news_train.loc[news_train['id'].isin(ids) , 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our data ready we perform preprocessing steps on it\n",
    "news_train = news_train.dropna()  # place this above the two cells\n",
    "label = news_train[\"label\"]  # Get a seperate columns for labels\n",
    "news_train = news_train.drop(\"label\", axis=1)\n",
    "news_train.set_index(\"id\", inplace=True)\n",
    "\n",
    "\n",
    "news_train[\"text\"] = news_train[\n",
    "    \"text\"\n",
    "].str.lower()  # convert the whole text to lower case to ensure uniformity\n",
    "\n",
    "news_train[\"text\"] = news_train[\"text\"].replace(\"[^A-Za-z\\s]\", \"\", regex=True)\n",
    "#Replace everything that is not letters or a space with a blank\n",
    "\n",
    "news_train[\"text\"] = news_train[\"text\"].str.split()  # split our text column to a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mohammadanas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# during this chunk cell, we just wrote a function to remove stopwords\n",
    "# and use porterstemmer to perform lemmatization. This function takes in a list and return a sentence\n",
    "\n",
    "ps = PorterStemmer()\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "def remove_stopwords_and_stem(x):\n",
    "    stopwds_lst = stopwords.words(\"english\")\n",
    "    sentence = \"\"\n",
    "    for i in x:\n",
    "        if i in stopwds_lst:\n",
    "            x.remove(i)\n",
    "    for k in range(len(x)):\n",
    "        word = ps.stem(x[k])\n",
    "        x[k] = word\n",
    "    for j in x:\n",
    "        sentence = sentence + j + \" \"\n",
    "    sentence_final = sentence[:-1]\n",
    "    return sentence_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train['text'] = news_train['text'].apply(remove_stopwords_and_stem)\n",
    "# we apply the above function to the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_comments = news_train['text'] \n",
    "# now we seperate the text into another series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a Bag of words model that take into account the the most frequently occurring unigrams and bigrams. \n",
    "# The reason for doing this is avoiding curse of dimensionality  \n",
    "cv = CountVectorizer(max_features=10000, ngram_range=(1,2)) \n",
    "cv.fit(text_comments) \n",
    "BOG = cv.transform(text_comments)\n",
    "BOG = BOG.toarray() # seperate BOG(bag of words as a seperate array)\n",
    "label = np.array(label) # seperate labels as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Generative model created in Step 2 to create synthetic data\n",
    "# In our case this is a Multinomial Naive Bayes Model ( for 2 classes as with our dataset, \n",
    "# this behaves like a Binomial Naive Bayes)\n",
    "# We have already identified and tuned our hyper parameters for this model. The Building of this \n",
    "# model is described in \"Training Naive Bayes.ipynb\". However, for generating synthetic data we train it on \n",
    "# the whole dataset rather than using only the train data. This will allow us to capture the \n",
    "# distibution of the sentences better and so we can generate a better synthetic data. The only point is that \n",
    "# we are just using the hyperparametre from that model rather than tuning them seperately. For our\n",
    "# model the hypermater is Alpha, a laplace smoothing constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = BOG\n",
    "\n",
    "Model = MultinomialNB(alpha=0.1)\n",
    "Model.fit(x_train, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lengths = np.sum(x_train,axis=1) # This gives us the length of each document in the sentence\n",
    "words = cv.get_feature_names_out() # This returns the feature words used to generate the Bag of words\n",
    "log_prob = Model.feature_log_prob_ # This returns log probabilities vectors of each feature given a class label (P(X|y))\n",
    "prob = np.exp(log_prob) # This exponentiates the log_probs to get probabilities\n",
    "class_prob = np.exp(Model.class_log_prior_) # returns class probabilites based on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56663932 0.43336068]\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18285, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(class_prob)\n",
    "print(Model.classes_)\n",
    "news_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the above information to generate a synthetic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the purpose of this function is to generate words from a bag of words vector.\n",
    "# By bag of words vector, we mean the horizontal vector corresponding to each sentence.\n",
    "# change sequence arguements just shuufle the order of the sentence (does not matter in \n",
    "# our case as our generative naive bayes is does not take order into account. I just added)\n",
    "def sentence(words, rep_vector, change_sequence=False):\n",
    "    assert isinstance(\n",
    "        change_sequence, bool\n",
    "    ), \"Please enter a Boolean for change_sequence\"\n",
    "    sentence_list = []\n",
    "    for i in range(len(words)):\n",
    "        char = words[i]\n",
    "        rep = rep_vector[0, i]\n",
    "        if rep != 0:\n",
    "            char_rep = char * rep\n",
    "            if rep == 1:\n",
    "                sentence_list.append(char_rep)\n",
    "            else:\n",
    "                chunks = [\n",
    "                    char_rep[i : i + 2] for i in range(0, len(char_rep), len(char))\n",
    "                ]\n",
    "                sentence_list = sentence_list + chunks\n",
    "    if change_sequence == False:\n",
    "        return \" \".join(sentence_list)\n",
    "    elif change_sequence == True:\n",
    "        sen_list = np.array(sentence_list.copy())\n",
    "        np.random.shuffle(sen_list)\n",
    "        return \" \".join(sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_labels = np.random.binomial(1, class_prob[1], 2000) # based on the class probabilities we create a 2000\n",
    "# labels randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_sentences = np.array([])\n",
    "synthetic_BOG = np.zeros(\n",
    "    [2000, 10000]\n",
    ")  # a place holder array to create a synthetic bag of words\n",
    "for i in range(len(synthetic_labels)):\n",
    "    current_label = synthetic_labels[i]  # takes the label\n",
    "    length_of_doc = np.random.choice(\n",
    "        doc_lengths\n",
    "    )  # takes a random length based on the lengths of document that occur in our original data\n",
    "    rep_vec = np.random.multinomial(\n",
    "        length_of_doc, prob[current_label], size=1\n",
    "    )  # takes the feature probabilities given the class label generates multinomial a vector that \n",
    "    # corresponds to a data entry or a document. This vector will indicates the \n",
    "    # number of words in each sentence.\n",
    "\n",
    "    synthetic_BOG[i] = rep_vec # append the vector to our placeholder vector for synthetic data  \n",
    "    synthetic_sentences = np.append(\n",
    "        synthetic_sentences, sentence(words, rep_vec, change_sequence=True)\n",
    "    ) # based on the vector generated above this code creates a sentence and adds it to the sentence array above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Synthetic bag of words and synthetic sentences array are the same \n",
    "# sentences but different representations. However, we will just use the \n",
    "# sentences data to test our models that we create in step 2 and step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_Data_Sentences = pd.DataFrame(synthetic_sentences,columns=['sentences'])\n",
    "synthetic_Data_Sentences['labels'] = pd.Series(synthetic_labels)\n",
    "## created datafram of setence synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_Data_Sentences.to_csv(\n",
    "    \"/Users/mohammadanas/Desktop/Duke MIDS/Fall 2021/NLP/NLP Final Project/Synthetic_Sentences.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "#Exporting to csv to test it on other models."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b380258cf79b42527fed6311333d79c1289944b72972a459157fc33b01639dbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
