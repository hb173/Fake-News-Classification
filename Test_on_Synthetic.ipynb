{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train on Synthetic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "34_d2xWxqvdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e39299-2e11-4514-9c8a-e0f0cfc8ace5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow import metrics\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "RAxduvK6q0Ab"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# import a naive bayes\n",
        "NaiveBayes_model = pickle.load(\n",
        "    open(\n",
        "        \"/content/gdrive/My Drive/NLP Project/NB_model.pkl\",\n",
        "        \"rb\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# import the count vectorizer for making Bag of Words\n",
        "Count_Vectorizer = pickle.load(\n",
        "    open(\n",
        "        \"/content/gdrive/My Drive/NLP Project/CV_BOG.pkl\",\n",
        "        \"rb\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# import a Tokenizer for assigning a unique integer to one\n",
        "Tokenizer1 =  pickle.load(\n",
        "    open(\n",
        "        \"/content/gdrive/My Drive/NLP Project/Text_Vec.pkl\",\n",
        "        \"rb\",\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "02CS1zu2q3Ke"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import neural network\n",
        "\n",
        "\n",
        "BiLSTM_Model = load_model(\n",
        "    \"/content/gdrive/My Drive/NLP Project/neural_network.h5\"\n",
        ")"
      ],
      "metadata": {
        "id": "w2YxIMTaq4Ft"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "fake_news_synthetic = pd.read_csv(\"/content/gdrive/My Drive/NLP Project/Synthetic_Sentences.csv\")\n",
        "fake_news_synthetic = fake_news_synthetic.dropna()"
      ],
      "metadata": {
        "id": "vHDXHMNxq60K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given that synthetic Sentences were created from the corpus after stemming and removing stop \n",
        "# words and other preprocessing steps like lowering strings, we dont have to do those preprocessing steps on it."
      ],
      "metadata": {
        "id": "eH9nvLgyrVF9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_text = fake_news_synthetic['sentences']\n",
        "synthetic_labels = fake_news_synthetic['labels']"
      ],
      "metadata": {
        "id": "gvjjnk6vrKG2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOG_synthetic = Count_Vectorizer.transform(fake_news_synthetic['sentences']) # We pass test input to transform into BOG, \n",
        "                                                    # CV is fitted on train and transformed on synthetic\n",
        "BOG_synthetic = BOG_synthetic.toarray() # seperate BOG(bag of words as a seperate array)\n",
        "label = np.array(synthetic_labels) # seperate labels as an array"
      ],
      "metadata": {
        "id": "A4kAwBZCtgjR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = NaiveBayes_model.predict(BOG_synthetic)\n",
        "print(classification_report(synthetic_labels, predicted))\n"
      ],
      "metadata": {
        "id": "otrAbM-AuE7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b501b4dc-cdae-4296-82c3-f8f7a606bf07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1131\n",
            "           1       0.97      0.99      0.98       866\n",
            "\n",
            "    accuracy                           0.98      1997\n",
            "   macro avg       0.98      0.98      0.98      1997\n",
            "weighted avg       0.98      0.98      0.98      1997\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_comments = list(synthetic_text) # make a list of all documents in the data\n",
        "one_hot_encoded = Tokenizer1.texts_to_sequences(text_comments)\n",
        "padded_vector = pad_sequences(one_hot_encoded, padding = 'post', maxlen= 500) #make a padded list\n",
        "input =np.array(padded_vector)\n",
        "output = np.array(synthetic_labels)   # convert to input and output for model   "
      ],
      "metadata": {
        "id": "But27DsfuJxN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BiLSTM_Model.evaluate(input, output) #test your model"
      ],
      "metadata": {
        "id": "NW6Btb2Oufu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860bd133-b2a5-4139-f2cf-6a402baa8837"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 13s 190ms/step - loss: 1.0137 - accuracy: 0.7551 - recall: 0.9642\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0136531591415405, 0.7551326751708984, 0.9642032384872437]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_prob = BiLSTM_Model.predict(input, batch_size=64)\n",
        "keras_predicted = np.where(predicted_prob > 0.5, 1,0)"
      ],
      "metadata": {
        "id": "u-kF5g99uj_V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(synthetic_labels, keras_predicted))"
      ],
      "metadata": {
        "id": "bVFBEisFumVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78694fc9-165a-439e-b4b8-4b0c18e3fa74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.60      0.73      1131\n",
            "           1       0.65      0.96      0.77       866\n",
            "\n",
            "    accuracy                           0.76      1997\n",
            "   macro avg       0.80      0.78      0.75      1997\n",
            "weighted avg       0.82      0.76      0.75      1997\n",
            "\n"
          ]
        }
      ]
    }
  ]
}